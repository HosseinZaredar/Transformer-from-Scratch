# Transformer from Scratch

An implementation of Transformers in PyTorch [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1AgLOnXB7E8V7MoZMHMhcpsDba4mJkURg#scrollTo=iQTSI_VANdHq).
<br>
A single-layer transformer encoder + a linear classifer is trained end-to-end for sentiment analysis on IMDb dataset (~70 Accuracy).<br>

### Todo
- [ ] Use pre-trained word embeddings like GloVe
- [ ] Use a deeper network for better accuracy

### Resources
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [CS224N | Lecture 9 - Self- Attention and Transformers](https://www.youtube.com/watch?v=ptuGllU5SQQ&list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ&index=9)
- [Aladdin Persson - Pytorch Transformers from Scratch](https://www.youtube.com/watch?v=U0s0f995w14)
- [Peter Bloem - Transformers](http://peterbloem.nl/blog/transformers)
- [PyTorch Sentiment Analysis](https://github.com/bentrevett/pytorch-sentiment-analysis)
